# Linear Probing with Swin Transformers

Compare custom Swin Transformer implementations against TIMM reference models on CIFAR-10, CIFAR-100, and ImageNet.

## ğŸš€ Quick Setup

### 1. Choose Dataset
Edit `config/__init__.py`:
```python
# DATASET = "cifar10"    
DATASET = "cifar100"     # â† Change this line
# DATASET = "imagenet"   
```

### 2. Choose Model & Training Settings
Edit the corresponding config file:

**For CIFAR-100** â†’ Edit `config/cifar100_config.py`:
```python
SWIN_CONFIG = {
    "variant": "tiny",  # Options: "tiny", "small", "base", "large"
}

TRAINING_CONFIG = {
    "learning_rate": 0.001,
    "num_epochs": 50,        # â† Change epochs here
    "warmup_epochs": 2,
}
```

**For CIFAR-10** â†’ Edit `config/cifar10_config.py`  
**For ImageNet** â†’ Edit `config/imagenet_config.py`

### 3. Set Data Path
In `config/__init__.py`:
```python
# Local:
# DATA_ROOT = "./datasets"

# Cluster:
DATA_ROOT = "/home/space/datasets"  # â† Uncomment for cluster
```

## ğŸƒ Running

### Local
```bash
python main.py
```

### Cluster
```bash
sbatch job.slurm
squeue -u $USER  # Check status
apptainer run --nv pml.sif python main.py
```

## ğŸ¯ Model Variants

| Variant | Parameters | Use Case |
|---------|------------|----------|
| `tiny`  | 29M        | Quick experiments |
| `small` | 50M        | Balanced performance |
| `base`  | 88M        | Full experiments |
| `large` | 197M       | Maximum accuracy |

**To switch models**: Just change `"variant": "tiny"` to `"variant": "base"` etc. in your config file.

## ğŸ“Š What You Get

The system automatically:
- Downloads TIMM pretrained models
- Creates matching custom Swin architecture  
- Transfers weights between models
- Trains both models with linear probing
- Compares final accuracies


## ğŸ“ Output

Results saved to `runs/run_XX/`:
```
â”œâ”€â”€ config.json                    # Your settings
â”œâ”€â”€ training.log                   # Full logs  
â”œâ”€â”€ training_curves_*.png          # Loss/accuracy plots
â”œâ”€â”€ confusion_matrix_*.png         # Test results
â””â”€â”€ results_*.json                 # Final metrics
```

