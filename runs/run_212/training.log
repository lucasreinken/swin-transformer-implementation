2025-12-15 02:21:39,873 - INFO - Logging initialized. Log file: runs/run_212/training.log
2025-12-15 02:21:40,010 - INFO - Experiment directory: runs/run_212
2025-12-15 02:21:40,012 - INFO - Setting random seeds for reproducibility (seed: 42)...
2025-12-15 02:21:40,032 - INFO - âœ… All seeds set to 42 (deterministic=False)
2025-12-15 02:21:40,351 - INFO - GPU memory cleared at startup. Available: 11.6GB
2025-12-15 02:21:40,353 - INFO - Using device: cuda
2025-12-15 02:21:40,354 - INFO - Training configuration: epochs=15, warmup=1, lr=0.0015
2025-12-15 02:21:40,356 - INFO - SWIN configuration: variant=tiny, use_shifted_window=True, use_relative_bias=True, use_absolute_pos_embed=False, use_hierarchical_merge=False, use_gradient_checkpointing=True
2025-12-15 02:21:40,357 - INFO - SWIN details: embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], window_size=7
2025-12-15 02:21:40,359 - INFO - Loading dataset...
2025-12-15 02:21:40,362 - INFO - Starting ImageNet data loading from root: /
2025-12-15 02:21:40,364 - INFO - Resolved root path: /
2025-12-15 02:21:40,365 - INFO - Root path exists: True
2025-12-15 02:21:40,366 - INFO - Root path is dir: True
2025-12-15 02:21:40,377 - INFO - Contents of /: ['/.exec', '/.run', '/.shell', '/.singularity.d', '/.test', '/bin', '/boot', '/dev', '/environment', '/etc', '/home', '/lib', '/lib64', '/media', '/mnt', '/opt', '/proc', '/requirements.txt', '/root', '/run', '/sbin', '/singularity', '/srv', '/sys', '/tmp', '/usr', '/var', '/meta', '/train_set', '/train_set_small', '/val_set', '/val_set_unlabeled']
2025-12-15 02:21:40,378 - INFO - Expected train_dir: /train_set, exists: True
2025-12-15 02:21:40,379 - INFO - Expected val_dir: /val_set, exists: True
2025-12-15 02:21:54,691 - INFO - Loaded ImageNet data from /: train=1281167, val=50000
2025-12-15 02:21:55,030 - INFO - Dataset loaded: train=100000 samples (447 batches), val=50000 samples (224 batches), test=50000 samples (224 batches)
2025-12-15 02:21:59,068 - INFO - Training SWIN from scratch
2025-12-15 02:21:59,074 - INFO - Initializing SWIN model from scratch...
2025-12-15 02:21:59,076 - INFO - Model architecture: SWIN
2025-12-15 02:21:59,078 - INFO - Model config: {'type': 'swin', 'variant': 'tiny', 'patch_size': 4, 'embed_dim': 96, 'depths': [2, 2, 6, 2], 'num_heads': [3, 6, 12, 24], 'window_size': 7, 'mlp_ratio': 4.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'projection_dropout': 0.0, 'drop_path_rate': 0.08, 'use_shifted_window': True, 'use_relative_bias': True, 'use_absolute_pos_embed': False, 'use_hierarchical_merge': False, 'use_gradient_checkpointing': True}
2025-12-15 02:22:00,017 - INFO - Model created with random initialization
2025-12-15 02:22:00,019 - INFO - Total parameters: 28,288,354
2025-12-15 02:22:00,021 - INFO - Trainable parameters: 28,288,354
2025-12-15 02:22:00,120 - INFO - Starting from-scratch training...
2025-12-15 02:22:00,122 - INFO - Optimizer: training all model parameters
2025-12-15 02:22:00,126 - INFO - LR Scheduler: cosine with 1 warmup epochs
2025-12-15 02:22:00,128 - INFO - Starting training...
2025-12-15 03:20:12,735 - INFO - Epoch 1/15: LR: 0.001500
2025-12-15 03:20:12,756 - INFO - Epoch 1/15: Train Loss: 6.8515, Val Loss: 6.7133, Val Acc: 0.51%
2025-12-15 03:20:31,511 - ERROR - Experiment failed with error: CUDA out of memory. Tried to allocate 1.01 GiB. GPU 0 has a total capacity of 11.60 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process has 10.59 GiB memory in use. Of the allocated memory 10.15 GiB is allocated by PyTorch, and 242.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-15 03:20:31,514 - ERROR - Full traceback:
Traceback (most recent call last):
  File "/home/pml04/swin_transformer/Machine-Learning-Project/main.py", line 230, in main
    run_from_scratch(
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/pipelines/from_scratch.py", line 210, in run_from_scratch
    criterion, lr_history, metrics_history = _train_single_model(
                                             ^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/pipelines/from_scratch.py", line 110, in _train_single_model
    run_training_loop(
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/training/trainer.py", line 165, in run_training_loop
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/training/trainer.py", line 73, in train_one_epoch
    loss.backward()
  File "/usr/local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.01 GiB. GPU 0 has a total capacity of 11.60 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process has 10.59 GiB memory in use. Of the allocated memory 10.15 GiB is allocated by PyTorch, and 242.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
