2025-11-22 00:25:28,185 - INFO - Logging initialized. Log file: runs/run_38/training.log
2025-11-22 00:25:28,228 - INFO - Experiment directory: runs/run_38
2025-11-22 00:25:28,427 - INFO - Setting random seeds for reproducibility (seed: 42)...
2025-11-22 00:25:28,440 - INFO - Random seeds set to 42 (deterministic=False)
2025-11-22 00:25:28,441 - INFO - Setting up device...
2025-11-22 00:25:28,442 - INFO - Using device: cuda
2025-11-22 00:25:28,444 - INFO - Using device: cuda
2025-11-22 00:25:28,445 - INFO - Training configuration: epochs=50, warmup=2, lr=0.001
2025-11-22 00:25:28,446 - INFO - Using pretrained model: swin_tiny_patch4_window7_224
2025-11-22 00:25:28,447 - INFO - Model architecture: Swin-Tiny
2025-11-22 00:25:28,448 - INFO - Model config: embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24]
2025-11-22 00:25:28,450 - INFO - Image size: 224x224, patch_size: 4x4
2025-11-22 00:25:28,451 - INFO - Loading dataset...
2025-11-22 00:25:30,889 - INFO - Dataset loaded: train=1303, val=261, test=313 batches
2025-11-22 00:25:30,891 - INFO - Initializing reference model...
2025-11-22 00:25:30,892 - INFO - Loading TIMM model: swin_tiny_patch4_window7_224 with pretrained weights
2025-11-22 00:25:31,417 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_tiny_patch4_window7_224.ms_in1k)
2025-11-22 00:25:31,718 - INFO - HTTP Request: HEAD https://huggingface.co/timm/swin_tiny_patch4_window7_224.ms_in1k/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2025-11-22 00:25:31,737 - INFO - [timm/swin_tiny_patch4_window7_224.ms_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-22 00:25:31,915 - INFO - Successfully loaded swin_tiny_patch4_window7_224 from TIMM
2025-11-22 00:25:31,917 - INFO - Encoder loaded: 768 output features
2025-11-22 00:25:31,919 - INFO - Created classification head: 768 -> 100 classes
2025-11-22 00:25:31,921 - INFO - Reference model created. Trainable params (head only): 78,436
2025-11-22 00:25:32,176 - INFO - Detected Swin Transformer architecture
2025-11-22 00:25:32,177 - INFO - Extracting model size from TIMM model name...
2025-11-22 00:25:32,179 - INFO - Detected model size: tiny
2025-11-22 00:25:32,180 - INFO - Will create custom model with: {'embed_dim': 96, 'depths': [2, 2, 6, 2], 'num_heads': [3, 6, 12, 24]}
2025-11-22 00:25:32,182 - INFO - Initializing custom Swin model (size: tiny)...
2025-11-22 00:25:32,183 - INFO - Custom model will match architecture: embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24]
2025-11-22 00:25:32,522 - INFO - Transferring weights from reference to custom encoder...
2025-11-22 00:25:32,523 - INFO - Weight transfer: SwinTransformer -> SwinTransformerModel
2025-11-22 00:25:32,538 - INFO - Weight transfer: 169 layers transferred.
2025-11-22 00:25:32,559 - INFO - Weight transfer completed: {'transferred': 169, 'missing': 0, 'size_mismatches': 0}
2025-11-22 00:25:32,561 - INFO - ✓ All expected weights transferred successfully
2025-11-22 00:25:32,562 - INFO - Custom model created. Trainable params (head only): 78,436
2025-11-22 00:25:32,566 - INFO - Starting reference model training...
2025-11-22 00:25:32,568 - INFO - Starting training...
2025-11-22 00:27:45,357 - INFO - Epoch 1/50: LR: 0.000550
2025-11-22 00:27:45,359 - INFO - Epoch 1/50: Train Loss: 3.5903, Val Loss: 2.5830, Val Acc: 60.75%
2025-11-22 00:29:57,241 - INFO - Epoch 2/50: LR: 0.001000
2025-11-22 00:29:57,242 - INFO - Epoch 2/50: Train Loss: 1.4175, Val Loss: 1.0003, Val Acc: 71.50%
2025-11-22 00:32:09,389 - INFO - Epoch 3/50: LR: 0.000999
2025-11-22 00:32:09,391 - INFO - Epoch 3/50: Train Loss: 0.9360, Val Loss: 0.8710, Val Acc: 74.08%
2025-11-22 00:34:21,455 - INFO - Epoch 4/50: LR: 0.000996
2025-11-22 00:34:21,470 - INFO - Epoch 4/50: Train Loss: 0.7888, Val Loss: 0.8365, Val Acc: 75.23%
2025-11-22 00:36:33,480 - INFO - Epoch 5/50: LR: 0.000990
2025-11-22 00:37:18,600 - INFO - Epoch 5/50: Train Loss: 0.7097, Val Loss: 0.8237, Val Acc: 75.75%, Test Loss: 0.8227, Test Acc: 75.94%
2025-11-22 00:39:30,768 - INFO - Epoch 6/50: LR: 0.000983
2025-11-22 00:39:30,791 - INFO - Epoch 6/50: Train Loss: 0.6571, Val Loss: 0.8189, Val Acc: 76.35%
2025-11-22 00:41:42,869 - INFO - Epoch 7/50: LR: 0.000973
2025-11-22 00:41:42,871 - INFO - Epoch 7/50: Train Loss: 0.6135, Val Loss: 0.8234, Val Acc: 76.04%
2025-11-22 00:43:55,251 - INFO - Epoch 8/50: LR: 0.000962
2025-11-22 00:43:55,253 - INFO - Epoch 8/50: Train Loss: 0.5847, Val Loss: 0.8244, Val Acc: 76.56%
2025-11-22 00:46:07,216 - INFO - Epoch 9/50: LR: 0.000948
2025-11-22 00:46:07,218 - INFO - Epoch 9/50: Train Loss: 0.5597, Val Loss: 0.8284, Val Acc: 76.34%
2025-11-22 00:48:19,369 - INFO - Epoch 10/50: LR: 0.000933
2025-11-22 00:48:19,371 - INFO - Early stopping triggered at epoch 10.
2025-11-22 00:48:19,372 - INFO - Training completed!
2025-11-22 00:48:19,373 - INFO - Reference model training completed!
2025-11-22 00:48:19,374 - INFO - Generating training curves...
2025-11-22 00:48:21,295 - INFO - Training curves saved as separate images with base name 'runs/run_38/training_curves_reference'
2025-11-22 00:48:21,297 - INFO - Generating confusion matrix on test set...
2025-11-22 00:49:18,452 - INFO - Performing final evaluation of reference model on test set...
2025-11-22 00:50:03,580 - INFO - Final Test Results of reference model: Loss: 0.8394, Accuracy: 76.43%
2025-11-22 00:50:03,582 - INFO - Generating LR schedule plot of reference model...
2025-11-22 00:50:04,632 - INFO - LR schedule plot saved to 'runs/run_38/lr_schedule_reference.png'
2025-11-22 00:50:04,634 - INFO - 
Final Test Results:
2025-11-22 00:50:04,636 - INFO - Loss: 0.8394
2025-11-22 00:50:04,637 - INFO - Accuracy: 76.43%
2025-11-22 00:50:04,639 - INFO - Precision: 76.99%
2025-11-22 00:50:04,641 - INFO - Recall: 76.43%
2025-11-22 00:50:04,643 - INFO - F1 Score: 76.43%
2025-11-22 00:50:04,654 - INFO - Experiment completed. Results saved to runs/run_38/results_reference.json
2025-11-22 00:50:04,658 - INFO - Experiment completed. Metadata saved to runs/run_38/metadata_reference.json
2025-11-22 00:50:05,004 - INFO - ✅ Model weights saved: trained_models/CIFAR100_final_model_reference_weights.pth
2025-11-22 00:50:05,006 - INFO - Starting custom model training...
2025-11-22 00:50:05,008 - INFO - Starting training...
2025-11-22 00:52:19,152 - INFO - Epoch 1/50: LR: 0.000550
2025-11-22 00:52:19,154 - INFO - Epoch 1/50: Train Loss: 3.5711, Val Loss: 2.5400, Val Acc: 60.30%
2025-11-22 00:54:32,570 - INFO - Epoch 2/50: LR: 0.001000
2025-11-22 00:54:32,572 - INFO - Epoch 2/50: Train Loss: 1.4230, Val Loss: 0.9990, Val Acc: 71.19%
2025-11-22 00:56:45,831 - INFO - Epoch 3/50: LR: 0.000999
2025-11-22 00:56:45,832 - INFO - Epoch 3/50: Train Loss: 0.9438, Val Loss: 0.8773, Val Acc: 74.03%
2025-11-22 00:58:59,123 - INFO - Epoch 4/50: LR: 0.000996
2025-11-22 00:58:59,125 - INFO - Epoch 4/50: Train Loss: 0.7957, Val Loss: 0.8216, Val Acc: 75.88%
2025-11-22 01:01:12,632 - INFO - Epoch 5/50: LR: 0.000990
2025-11-22 01:01:57,536 - INFO - Epoch 5/50: Train Loss: 0.7156, Val Loss: 0.8071, Val Acc: 76.08%, Test Loss: 0.8044, Test Acc: 76.42%
2025-11-22 01:04:10,880 - INFO - Epoch 6/50: LR: 0.000983
2025-11-22 01:04:10,882 - INFO - Epoch 6/50: Train Loss: 0.6618, Val Loss: 0.8187, Val Acc: 76.11%
2025-11-22 01:06:23,122 - INFO - Epoch 7/50: LR: 0.000973
2025-11-22 01:06:23,124 - INFO - Epoch 7/50: Train Loss: 0.6182, Val Loss: 0.8204, Val Acc: 76.19%
2025-11-22 01:08:32,844 - INFO - Epoch 8/50: LR: 0.000962
2025-11-22 01:08:32,845 - INFO - Epoch 8/50: Train Loss: 0.5847, Val Loss: 0.8183, Val Acc: 76.40%
2025-11-22 01:10:42,405 - INFO - Epoch 9/50: LR: 0.000948
2025-11-22 01:10:42,425 - INFO - Epoch 9/50: Train Loss: 0.5612, Val Loss: 0.8318, Val Acc: 76.34%
2025-11-22 01:12:52,097 - INFO - Epoch 10/50: LR: 0.000933
2025-11-22 01:12:52,099 - INFO - Early stopping triggered at epoch 10.
2025-11-22 01:12:52,100 - INFO - Training completed!
2025-11-22 01:12:52,102 - INFO - Custom model training completed!
2025-11-22 01:12:52,103 - INFO - Generating training curves...
2025-11-22 01:12:53,963 - INFO - Training curves saved as separate images with base name 'runs/run_38/training_curves_custom'
2025-11-22 01:12:53,965 - INFO - Generating confusion matrix on test set...
2025-11-22 01:13:50,565 - INFO - Performing final evaluation of custom model on test set...
2025-11-22 01:14:34,725 - INFO - Final Test Results of custom model: Loss: 0.8269, Accuracy: 76.36%
2025-11-22 01:14:34,727 - INFO - Generating LR schedule plot of custom model...
2025-11-22 01:14:35,144 - INFO - LR schedule plot saved to 'runs/run_38/lr_schedule_custom.png'
2025-11-22 01:14:35,146 - INFO - 
Final Test Results:
2025-11-22 01:14:35,148 - INFO - Loss: 0.8269
2025-11-22 01:14:35,149 - INFO - Accuracy: 76.36%
2025-11-22 01:14:35,151 - INFO - Precision: 76.73%
2025-11-22 01:14:35,152 - INFO - Recall: 76.36%
2025-11-22 01:14:35,154 - INFO - F1 Score: 76.31%
2025-11-22 01:14:35,164 - INFO - Experiment completed. Results saved to runs/run_38/results_custom.json
2025-11-22 01:14:35,168 - INFO - Experiment completed. Metadata saved to runs/run_38/metadata_custom.json
2025-11-22 01:14:35,496 - INFO - ✅ Model weights saved: trained_models/CIFAR100_final_model_custom_weights.pth
2025-11-22 01:14:35,498 - INFO - === MODEL COMPARISON RESULTS (Linear Probing on CIFAR-100) ===
2025-11-22 01:14:35,499 - INFO - Reference (HF): 76.43%
2025-11-22 01:14:35,500 - INFO - Custom        : 76.36%
2025-11-22 01:14:35,501 - INFO - Difference    : 0.07% (custom - reference)
2025-11-22 01:14:35,502 - INFO - Linear probing experiment completed successfully!
